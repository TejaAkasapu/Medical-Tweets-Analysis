{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "nn_trial.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "qIKZrgj-PZLB",
        "colab_type": "code",
        "outputId": "272774ad-47fd-45ff-c1f8-d17a186674f7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        }
      },
      "source": [
        "!pip install emoji"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting emoji\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/40/8d/521be7f0091fe0f2ae690cc044faf43e3445e0ff33c574eae752dd7e39fa/emoji-0.5.4.tar.gz (43kB)\n",
            "\r\u001b[K     |███████▌                        | 10kB 25.1MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 20kB 1.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████▋         | 30kB 2.1MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▏ | 40kB 1.6MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 51kB 1.6MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: emoji\n",
            "  Building wheel for emoji (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for emoji: filename=emoji-0.5.4-cp36-none-any.whl size=42176 sha256=4daf4bfc146b7ac60e8c1fd71a37402989c1e59c1f80bcd0fecbda023ef999ce\n",
            "  Stored in directory: /root/.cache/pip/wheels/2a/a9/0a/4f8e8cce8074232aba240caca3fade315bb49fac68808d1a9c\n",
            "Successfully built emoji\n",
            "Installing collected packages: emoji\n",
            "Successfully installed emoji-0.5.4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZpOyTneOjJBw",
        "colab_type": "code",
        "outputId": "79591ead-58ac-4a3a-9633-00b1918c533f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "#deal with tensors\n",
        "import torch   \n",
        "\n",
        "#handling text data\n",
        "from torchtext import data   \n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "import sys\n",
        "import os\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "import csv\n",
        "import datetime\n",
        "from bs4 import BeautifulSoup\n",
        "import itertools\n",
        "import emoji"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tnfbiJjpUMn6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#####################################################################################\n",
        "#\n",
        "# DATA CLEANING\n",
        "#\n",
        "#####################################################################################\n",
        "\n",
        "# emoticons\n",
        "def load_dict_smileys():\n",
        "    \n",
        "    return {\n",
        "        \":‑)\":\"smiley\",\n",
        "  \n",
        "      \":-]\":\"smiley\",\n",
        "        \":-3\":\"smiley\",\n",
        "        \":->\":\"smiley\",\n",
        "        \"8-)\":\"smiley\",\n",
        "        \":-}\":\"smiley\",\n",
        "        \":)\":\"smiley\",\n",
        "        \":]\":\"smiley\",\n",
        "        \":3\":\"smiley\",\n",
        "        \":>\":\"smiley\",\n",
        "        \"8)\":\"smiley\",\n",
        "        \":}\":\"smiley\",\n",
        "        \":o)\":\"smiley\",\n",
        "        \":c)\":\"smiley\",\n",
        "        \":^)\":\"smiley\",\n",
        "        \"=]\":\"smiley\",\n",
        "        \"=)\":\"smiley\",\n",
        "        \":-))\":\"smiley\",\n",
        "        \":‑D\":\"smiley\",\n",
        "        \"8‑D\":\"smiley\",\n",
        "        \"x‑D\":\"smiley\",\n",
        "        \"X‑D\":\"smiley\",\n",
        "        \":D\":\"smiley\",\n",
        "        \"8D\":\"smiley\",\n",
        "        \"xD\":\"smiley\",\n",
        "        \"XD\":\"smiley\",\n",
        "        \":‑(\":\"sad\",\n",
        "        \":‑c\":\"sad\",\n",
        "        \":‑<\":\"sad\",\n",
        "        \":‑[\":\"sad\",\n",
        "        \":(\":\"sad\",\n",
        "        \":c\":\"sad\",\n",
        "        \":<\":\"sad\",\n",
        "        \":[\":\"sad\",\n",
        "        \":-||\":\"sad\",\n",
        "        \">:[\":\"sad\",\n",
        "        \":{\":\"sad\",\n",
        "        \":@\":\"sad\",\n",
        "        \">:(\":\"sad\",\n",
        "        \":'‑(\":\"sad\",\n",
        "        \":'(\":\"sad\",\n",
        "        \":‑P\":\"playful\",\n",
        "        \"X‑P\":\"playful\",\n",
        "        \"x‑p\":\"playful\",\n",
        "        \":‑p\":\"playful\",\n",
        "        \":‑Þ\":\"playful\",\n",
        "        \":‑þ\":\"playful\",\n",
        "        \":‑b\":\"playful\",\n",
        "        \":P\":\"playful\",\n",
        "        \"XP\":\"playful\",\n",
        "        \"xp\":\"playful\",\n",
        "        \":p\":\"playful\",\n",
        "        \":Þ\":\"playful\",\n",
        "        \":þ\":\"playful\",\n",
        "        \":b\":\"playful\",\n",
        "        \"<3\":\"love\"\n",
        "        }\n",
        "\n",
        "# self defined contractions\n",
        "def load_dict_contractions():\n",
        "    \n",
        "    return {\n",
        "        \"ain't\":\"is not\",\n",
        "        \"amn't\":\"am not\",\n",
        "        \"aren't\":\"are not\",\n",
        "        \"can't\":\"cannot\",\n",
        "        \"'cause\":\"because\",\n",
        "        \"couldn't\":\"could not\",\n",
        "        \"couldn't've\":\"could not have\",\n",
        "        \"could've\":\"could have\",\n",
        "        \"daren't\":\"dare not\",\n",
        "        \"daresn't\":\"dare not\",\n",
        "        \"dasn't\":\"dare not\",\n",
        "        \"didn't\":\"did not\",\n",
        "        \"doesn't\":\"does not\",\n",
        "        \"don't\":\"do not\",\n",
        "        \"e'er\":\"ever\",\n",
        "        \"em\":\"them\",\n",
        "        \"everyone's\":\"everyone is\",\n",
        "        \"finna\":\"fixing to\",\n",
        "        \"gimme\":\"give me\",\n",
        "        \"gonna\":\"going to\",\n",
        "        \"gon't\":\"go not\",\n",
        "        \"gotta\":\"got to\",\n",
        "        \"hadn't\":\"had not\",\n",
        "        \"hasn't\":\"has not\",\n",
        "        \"haven't\":\"have not\",\n",
        "        \"he'd\":\"he would\",\n",
        "        \"he'll\":\"he will\",\n",
        "        \"he's\":\"he is\",\n",
        "        \"he've\":\"he have\",\n",
        "        \"how'd\":\"how would\",\n",
        "        \"how'll\":\"how will\",\n",
        "        \"how're\":\"how are\",\n",
        "        \"how's\":\"how is\",\n",
        "        \"I'd\":\"I would\",\n",
        "        \"I'll\":\"I will\",\n",
        "        \"I'm\":\"I am\",\n",
        "        \"I'm'a\":\"I am about to\",\n",
        "        \"I'm'o\":\"I am going to\",\n",
        "        \"isn't\":\"is not\",\n",
        "        \"it'd\":\"it would\",\n",
        "        \"it'll\":\"it will\",\n",
        "        \"it's\":\"it is\",\n",
        "        \"I've\":\"I have\",\n",
        "        \"kinda\":\"kind of\",\n",
        "        \"let's\":\"let us\",\n",
        "        \"mayn't\":\"may not\",\n",
        "        \"may've\":\"may have\",\n",
        "        \"mightn't\":\"might not\",\n",
        "        \"might've\":\"might have\",\n",
        "        \"mustn't\":\"must not\",\n",
        "        \"mustn't've\":\"must not have\",\n",
        "        \"must've\":\"must have\",\n",
        "        \"needn't\":\"need not\",\n",
        "        \"ne'er\":\"never\",\n",
        "        \"o'\":\"of\",\n",
        "        \"o'er\":\"over\",\n",
        "        \"ol'\":\"old\",\n",
        "        \"oughtn't\":\"ought not\",\n",
        "        \"shalln't\":\"shall not\",\n",
        "        \"shan't\":\"shall not\",\n",
        "        \"she'd\":\"she would\",\n",
        "        \"she'll\":\"she will\",\n",
        "        \"she's\":\"she is\",\n",
        "        \"shouldn't\":\"should not\",\n",
        "        \"shouldn't've\":\"should not have\",\n",
        "        \"should've\":\"should have\",\n",
        "        \"somebody's\":\"somebody is\",\n",
        "        \"someone's\":\"someone is\",\n",
        "        \"something's\":\"something is\",\n",
        "        \"that'd\":\"that would\",\n",
        "        \"that'll\":\"that will\",\n",
        "        \"that're\":\"that are\",\n",
        "        \"that's\":\"that is\",\n",
        "        \"there'd\":\"there would\",\n",
        "        \"there'll\":\"there will\",\n",
        "        \"there're\":\"there are\",\n",
        "        \"there's\":\"there is\",\n",
        "        \"these're\":\"these are\",\n",
        "        \"they'd\":\"they would\",\n",
        "        \"they'll\":\"they will\",\n",
        "        \"they're\":\"they are\",\n",
        "        \"they've\":\"they have\",\n",
        "        \"this's\":\"this is\",\n",
        "        \"those're\":\"those are\",\n",
        "        \"'tis\":\"it is\",\n",
        "        \"'twas\":\"it was\",\n",
        "        \"wanna\":\"want to\",\n",
        "        \"wasn't\":\"was not\",\n",
        "        \"we'd\":\"we would\",\n",
        "        \"we'd've\":\"we would have\",\n",
        "        \"we'll\":\"we will\",\n",
        "        \"we're\":\"we are\",\n",
        "        \"weren't\":\"were not\",\n",
        "        \"we've\":\"we have\",\n",
        "        \"what'd\":\"what did\",\n",
        "        \"what'll\":\"what will\",\n",
        "        \"what're\":\"what are\",\n",
        "        \"what's\":\"what is\",\n",
        "        \"what've\":\"what have\",\n",
        "        \"when's\":\"when is\",\n",
        "        \"where'd\":\"where did\",\n",
        "        \"where're\":\"where are\",\n",
        "        \"where's\":\"where is\",\n",
        "        \"where've\":\"where have\",\n",
        "        \"which's\":\"which is\",\n",
        "        \"who'd\":\"who would\",\n",
        "        \"who'd've\":\"who would have\",\n",
        "        \"who'll\":\"who will\",\n",
        "        \"who're\":\"who are\",\n",
        "        \"who's\":\"who is\",\n",
        "        \"who've\":\"who have\",\n",
        "        \"why'd\":\"why did\",\n",
        "        \"why're\":\"why are\",\n",
        "        \"why's\":\"why is\",\n",
        "        \"won't\":\"will not\",\n",
        "        \"wouldn't\":\"would not\",\n",
        "        \"would've\":\"would have\",\n",
        "        \"y'all\":\"you all\",\n",
        "        \"you'd\":\"you would\",\n",
        "        \"you'll\":\"you will\",\n",
        "        \"you're\":\"you are\",\n",
        "        \"you've\":\"you have\",\n",
        "        \"Whatcha\":\"What are you\",\n",
        "        \"luv\":\"love\",\n",
        "        \"sux\":\"sucks\"\n",
        "        }"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ifa0GG8_kgMa",
        "colab_type": "code",
        "outputId": "8984fa96-5c59-496e-b54b-89f8e184b1f9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YwoDcJI9rHRs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import re\n",
        "import string\n",
        "from bs4 import BeautifulSoup\n",
        "\n",
        "#for tweet in tweet_data:\n",
        "def preprocess_tweet(tweet):\n",
        "    #Escaping HTML characters\n",
        "    tweet = BeautifulSoup(tweet).get_text()\n",
        "   \n",
        "    #Special case not handled previously.\n",
        "    tweet = tweet.replace('\\x92',\"'\")\n",
        "    \n",
        "    #Removal of hastags/account\n",
        "    tweet = ' '.join(re.sub(\"(@[A-Za-z0-9]+)|(#[A-Za-z0-9]+)\", \" \", tweet).split())\n",
        "    \n",
        "    #Removal of address\n",
        "    tweet = ' '.join(re.sub(\"(\\w+:\\/\\/\\S+)\", \" \", tweet).split())\n",
        "    \n",
        "    #Removal of Punctuation\n",
        "    tweet = ' '.join(re.sub(\"[\\.\\,\\!\\?\\<\\>\\:\\;\\-\\=]\", \" \", tweet).split())\n",
        "    \n",
        "    #Lower case\n",
        "    tweet = tweet.lower()\n",
        "    \n",
        "    #CONTRACTIONS source: https://en.wikipedia.org/wiki/Contraction_%28grammar%29\n",
        "    CONTRACTIONS = load_dict_contractions()\n",
        "    tweet = tweet.replace(\"’\",\"'\")\n",
        "    words = tweet.split()\n",
        "    reformed = [CONTRACTIONS[word] if word in CONTRACTIONS else word for word in words]\n",
        "    tweet = \" \".join(reformed)\n",
        "    \n",
        "    # Standardizing words\n",
        "    tweet = ''.join(''.join(s)[:2] for _, s in itertools.groupby(tweet))\n",
        "    \n",
        "    #Deal with emoticons source: https://en.wikipedia.org/wiki/List_of_emoticons\n",
        "    SMILEY = load_dict_smileys()  \n",
        "    words = tweet.split()\n",
        "    reformed = [SMILEY[word] if word in SMILEY else word for word in words]\n",
        "    tweet = \" \".join(reformed)\n",
        "    \n",
        "    #Deal with emojis\n",
        "    tweet = emoji.demojize(tweet)\n",
        "\n",
        "    tweet = tweet.replace(\":\",\" \")\n",
        "    tweet = ' '.join(tweet.split())\n",
        "\n",
        "    return tweet\n",
        "    \n",
        "        \n",
        "#     # remove special characters, numbers, punctuations\n",
        "#     text = text.replace(\"[^a-zA-Z#]\", \" \")\n",
        "#     # Additional clean up : removing words less than 3 chars, and remove space at the beginning and the end\n",
        "#     text = re.sub(r'\\W*\\b\\w{1,3}\\b', '', text)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2icyEytaOTqm",
        "colab_type": "code",
        "outputId": "5d5b916f-210a-4f04-809f-36bf470b1b5a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 384
        }
      },
      "source": [
        "count = 0\n",
        "usecols = (2,4)\n",
        "dataframe = pd.read_table(\"/content/task1_training.tsv\",usecols=usecols)\n",
        "with open('SE_train.tsv', 'w') as out_file:\n",
        "  tsv_writer = csv.writer(out_file, delimiter='\\t')\n",
        "  tsv_writer.writerow(['text','label'])\n",
        "  for tweet in dataframe.iterrows():\n",
        "    if tweet[1][1] == 0:\n",
        "      count = count+1\n",
        "    if tweet[1][1] == 0 and count > 1000:\n",
        "      continue\n",
        "    tsv_writer.writerow([preprocess_tweet(tweet[1][0]), str(tweet[1][1])])\n",
        "    "
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/bs4/__init__.py:336: UserWarning: \"https://t.co/oewqnWJA4k\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
            "  ' that document to Beautiful Soup.' % decoded_markup\n",
            "/usr/local/lib/python3.6/dist-packages/bs4/__init__.py:336: UserWarning: \"https://t.co/29HB3YRChW\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
            "  ' that document to Beautiful Soup.' % decoded_markup\n",
            "/usr/local/lib/python3.6/dist-packages/bs4/__init__.py:336: UserWarning: \"https://t.co/SrTqQTcHuT\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
            "  ' that document to Beautiful Soup.' % decoded_markup\n",
            "/usr/local/lib/python3.6/dist-packages/bs4/__init__.py:336: UserWarning: \"http://t.co/tGe0fGhtwa\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
            "  ' that document to Beautiful Soup.' % decoded_markup\n",
            "/usr/local/lib/python3.6/dist-packages/bs4/__init__.py:336: UserWarning: \"https://t.co/sFfnztCggN\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
            "  ' that document to Beautiful Soup.' % decoded_markup\n",
            "/usr/local/lib/python3.6/dist-packages/bs4/__init__.py:336: UserWarning: \"https://t.co/rHxH6K7pVG\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
            "  ' that document to Beautiful Soup.' % decoded_markup\n",
            "/usr/local/lib/python3.6/dist-packages/bs4/__init__.py:336: UserWarning: \"https://t.co/gzSfdgQpKE\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
            "  ' that document to Beautiful Soup.' % decoded_markup\n",
            "/usr/local/lib/python3.6/dist-packages/bs4/__init__.py:336: UserWarning: \"https://t.co/W3Lj5TRi3C\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
            "  ' that document to Beautiful Soup.' % decoded_markup\n",
            "/usr/local/lib/python3.6/dist-packages/bs4/__init__.py:336: UserWarning: \"http://t.co/bNfwDkhGkU\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
            "  ' that document to Beautiful Soup.' % decoded_markup\n",
            "/usr/local/lib/python3.6/dist-packages/bs4/__init__.py:336: UserWarning: \"https://t.co/nidyKpR7oC\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
            "  ' that document to Beautiful Soup.' % decoded_markup\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fZXI3oxWP1Cs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "usecols = (2,4)\n",
        "dataframe = pd.read_table(\"/content/task1_validation.tsv\",usecols=usecols)\n",
        "with open('SE_valid.tsv', 'w') as out_file:\n",
        "  tsv_writer = csv.writer(out_file, delimiter='\\t')\n",
        "  tsv_writer.writerow(['text','label'])\n",
        "  for tweet in dataframe.iterrows():\n",
        "    if tweet[1][1] == 1:\n",
        "      tsv_writer.writerow([preprocess_tweet(tweet[1][0]), str(tweet[1][1])])\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z2_E41HNju_q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Reproducing same results\n",
        "SEED = 2019\n",
        "\n",
        "#Torch\n",
        "torch.manual_seed(SEED)\n",
        "\n",
        "#Cuda algorithms\n",
        "torch.backends.cudnn.deterministic = True "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0NWISrdjjx0e",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "TEXT = data.Field(tokenize='spacy',batch_first=True, lower=True,  include_lengths=True)\n",
        "LABEL = data.LabelField(dtype = torch.float,batch_first=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eTzdUzk2j1ni",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "fields = [('text',TEXT), ('label', LABEL)]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-8sJ3Fphj4cu",
        "colab_type": "code",
        "outputId": "ef77dc62-ea9f-4fa8-e26c-49b3b3cd8607",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "#loading custom dataset\n",
        "train_data = data.TabularDataset(path = '/content/SE_train.tsv',format = 'tsv',fields = fields,skip_header = True)\n",
        "valid_data = data.TabularDataset(path = '/content/SE_valid.tsv',format = 'tsv',fields = fields,skip_header = True)\n",
        "\n",
        "#print preprocessed text\n",
        "print(vars(train_data.examples[0]))"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'text': ['these', 'new', 'anti', 'anxiety', 'meds', 'make', 'me', 'so', 'sleepy', 'sleeping_face', 'zzz', 'not', 'sure', 'if', 'it', 'will', 'work', 'out', 'for', 'me', 'but', 'i', \"'m\", 'so', 'tired', 'of', 'always', 'switching', 'meds', 'unamused_face'], 'label': '1'}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RVchTZfJlL3i",
        "colab_type": "code",
        "outputId": "ef3b7daa-36c8-4b66-9e6f-1c8c8843a4af",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 399
        }
      },
      "source": [
        "#initialize glove embeddings\n",
        "TEXT.build_vocab(train_data,min_freq=3,vectors = \"glove.6B.100d\")  \n",
        "LABEL.build_vocab(train_data)\n",
        "\n",
        "#No. of unique tokens in text\n",
        "print(\"Size of TEXT vocabulary:\",len(TEXT.vocab))\n",
        "\n",
        "#No. of unique tokens in label\n",
        "print(\"Size of LABEL vocabulary:\",len(LABEL.vocab))\n",
        "\n",
        "#Commonly used words\n",
        "print(TEXT.vocab.freqs.most_common(10))  \n",
        "\n",
        "#Word dictionary\n",
        "print(TEXT.vocab.stoi) "
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            ".vector_cache/wiki.simple.vec: 0.00B [00:00, ?B/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "error",
          "ename": "HTTPError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mHTTPError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-18-f728ea1b594c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mTEXT\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild_vocab\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmin_freq\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvectors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"fasttext.simple.300d\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mLABEL\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild_vocab\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m#No. of unique tokens in text\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Size of TEXT vocabulary:\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTEXT\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvocab\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torchtext/data/field.py\u001b[0m in \u001b[0;36mbuild_vocab\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    271\u001b[0m                             self.eos_token]\n\u001b[1;32m    272\u001b[0m             if tok is not None))\n\u001b[0;32m--> 273\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvocab\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvocab_cls\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcounter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mspecials\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mspecials\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    274\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    275\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mnumericalize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torchtext/vocab.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, counter, max_size, min_freq, specials, vectors, unk_init, vectors_cache, specials_first)\u001b[0m\n\u001b[1;32m     86\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvectors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mvectors\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 88\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_vectors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvectors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munk_init\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0munk_init\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcache\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvectors_cache\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     89\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0munk_init\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mvectors_cache\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torchtext/vocab.py\u001b[0m in \u001b[0;36mload_vectors\u001b[0;34m(self, vectors, **kwargs)\u001b[0m\n\u001b[1;32m    145\u001b[0m                         \"vectors are {}\".format(\n\u001b[1;32m    146\u001b[0m                             vector, list(pretrained_aliases.keys())))\n\u001b[0;32m--> 147\u001b[0;31m                 \u001b[0mvectors\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpretrained_aliases\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mvector\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    148\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvector\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mVectors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m                 raise ValueError(\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torchtext/vocab.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, language, **kwargs)\u001b[0m\n\u001b[1;32m    409\u001b[0m         \u001b[0murl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0murl_base\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlanguage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    410\u001b[0m         \u001b[0mname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbasename\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 411\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mFastText\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    412\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    413\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torchtext/vocab.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, name, cache, url, unk_init, max_vectors)\u001b[0m\n\u001b[1;32m    278\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    279\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munk_init\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0munk_init\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0munk_init\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 280\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcache\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_vectors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_vectors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    281\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    282\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__getitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtoken\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torchtext/vocab.py\u001b[0m in \u001b[0;36mcache\u001b[0;34m(self, name, cache, url, max_vectors)\u001b[0m\n\u001b[1;32m    311\u001b[0m                     \u001b[0;32mwith\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0munit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'B'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munit_scale\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mminiters\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdesc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdest\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    312\u001b[0m                         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 313\u001b[0;31m                             \u001b[0murlretrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreporthook\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreporthook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    314\u001b[0m                         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# remove the partial zip file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    315\u001b[0m                             \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mremove\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/urllib/request.py\u001b[0m in \u001b[0;36murlretrieve\u001b[0;34m(url, filename, reporthook, data)\u001b[0m\n\u001b[1;32m    246\u001b[0m     \u001b[0murl_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msplittype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    247\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 248\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0mcontextlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclosing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murlopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    249\u001b[0m         \u001b[0mheaders\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/urllib/request.py\u001b[0m in \u001b[0;36murlopen\u001b[0;34m(url, data, timeout, cafile, capath, cadefault, context)\u001b[0m\n\u001b[1;32m    221\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    222\u001b[0m         \u001b[0mopener\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_opener\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 223\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mopener\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    224\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    225\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0minstall_opener\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopener\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/urllib/request.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(self, fullurl, data, timeout)\u001b[0m\n\u001b[1;32m    530\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mprocessor\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprocess_response\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprotocol\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m             \u001b[0mmeth\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocessor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmeth_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmeth\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/urllib/request.py\u001b[0m in \u001b[0;36mhttp_response\u001b[0;34m(self, request, response)\u001b[0m\n\u001b[1;32m    640\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m200\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0mcode\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m300\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    641\u001b[0m             response = self.parent.error(\n\u001b[0;32m--> 642\u001b[0;31m                 'http', request, response, code, msg, hdrs)\n\u001b[0m\u001b[1;32m    643\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    644\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/urllib/request.py\u001b[0m in \u001b[0;36merror\u001b[0;34m(self, proto, *args)\u001b[0m\n\u001b[1;32m    568\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhttp_err\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    569\u001b[0m             \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'default'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'http_error_default'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0morig_args\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 570\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_chain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    571\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    572\u001b[0m \u001b[0;31m# XXX probably also want an abstract factory that knows when it makes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/urllib/request.py\u001b[0m in \u001b[0;36m_call_chain\u001b[0;34m(self, chain, kind, meth_name, *args)\u001b[0m\n\u001b[1;32m    502\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhandler\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mhandlers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    503\u001b[0m             \u001b[0mfunc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmeth_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 504\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    505\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mresult\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    506\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/urllib/request.py\u001b[0m in \u001b[0;36mhttp_error_default\u001b[0;34m(self, req, fp, code, msg, hdrs)\u001b[0m\n\u001b[1;32m    648\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mHTTPDefaultErrorHandler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBaseHandler\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    649\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mhttp_error_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmsg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhdrs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 650\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mHTTPError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfull_url\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmsg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhdrs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    651\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    652\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mHTTPRedirectHandler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBaseHandler\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mHTTPError\u001b[0m: HTTP Error 301: Moved Permanently"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RZdAGLBjlOts",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#check whether cuda is available\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')  \n",
        "\n",
        "#set batch size\n",
        "BATCH_SIZE = 64\n",
        "\n",
        "#Load an iterator\n",
        "train_iterator, valid_iterator = data.BucketIterator.splits(\n",
        "    (train_data, valid_data), \n",
        "    batch_size = BATCH_SIZE,\n",
        "    sort_key = lambda x: len(x.text),\n",
        "    sort_within_batch=True,\n",
        "    device = device)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0C2AjXRGlOxA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "class classifier(nn.Module):\n",
        "    \n",
        "    #define all the layers used in model\n",
        "    def __init__(self, vocab_size, embedding_dim, hidden_dim, output_dim, n_layers, \n",
        "                 bidirectional, dropout):\n",
        "        \n",
        "        #Constructor\n",
        "        super().__init__()          \n",
        "        \n",
        "        #embedding layer\n",
        "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
        "        \n",
        "        #lstm layer\n",
        "        self.lstm = nn.LSTM(embedding_dim, \n",
        "                           hidden_dim, \n",
        "                           num_layers=n_layers, \n",
        "                           bidirectional=bidirectional, \n",
        "                           dropout=dropout,\n",
        "                           batch_first=True)\n",
        "        \n",
        "        #dense layer\n",
        "        self.fc = nn.Linear(hidden_dim * 2, output_dim)\n",
        "        \n",
        "        #activation function\n",
        "        self.act = nn.Sigmoid()\n",
        "        \n",
        "    def forward(self, text, text_lengths):\n",
        "        \n",
        "        #text = [batch size,sent_length]\n",
        "        embedded = self.embedding(text)\n",
        "        #embedded = [batch size, sent_len, emb dim]\n",
        "      \n",
        "        #packed sequence\n",
        "        packed_embedded = nn.utils.rnn.pack_padded_sequence(embedded, text_lengths,batch_first=True)\n",
        "        \n",
        "        packed_output, (hidden, cell) = self.lstm(packed_embedded)\n",
        "        #hidden = [batch size, num layers * num directions,hid dim]\n",
        "        #cell = [batch size, num layers * num directions,hid dim]\n",
        "        \n",
        "        #concat the final forward and backward hidden state\n",
        "        hidden = torch.cat((hidden[-2,:,:], hidden[-1,:,:]), dim = 1)\n",
        "                \n",
        "        #hidden = [batch size, hid dim * num directions]\n",
        "        dense_outputs=self.fc(hidden)\n",
        "\n",
        "        #Final activation function\n",
        "        outputs=self.act(dense_outputs)\n",
        "        \n",
        "        return outputs"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B9dcueJElO0P",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#define hyperparameters\n",
        "size_of_vocab = len(TEXT.vocab)\n",
        "embedding_dim = 100\n",
        "num_hidden_nodes = 32\n",
        "num_output_nodes = 1\n",
        "num_layers = 2\n",
        "bidirection = True\n",
        "dropout = 0.2\n",
        "\n",
        "#instantiate the model\n",
        "model = classifier(size_of_vocab, embedding_dim, num_hidden_nodes,num_output_nodes, num_layers, \n",
        "                   bidirectional = True, dropout = dropout)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3H5OYzjglO31",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 358
        },
        "outputId": "afc8ac3a-5100-44f6-9e17-9d79cb7ff028"
      },
      "source": [
        "\n",
        "#architecture\n",
        "print(model)\n",
        "\n",
        "#No. of trianable parameters\n",
        "def count_parameters(model):\n",
        "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "    \n",
        "print(f'The model has {count_parameters(model):,} trainable parameters')\n",
        "\n",
        "#Initialize the pretrained embedding\n",
        "pretrained_embeddings = TEXT.vocab.vectors\n",
        "model.embedding.weight.data.copy_(pretrained_embeddings)\n",
        "\n",
        "print(pretrained_embeddings.shape)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "classifier(\n",
            "  (embedding): Embedding(800, 100)\n",
            "  (lstm): LSTM(100, 32, num_layers=2, batch_first=True, dropout=0.2, bidirectional=True)\n",
            "  (fc): Linear(in_features=64, out_features=1, bias=True)\n",
            "  (act): Sigmoid()\n",
            ")\n",
            "The model has 139,457 trainable parameters\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-16-846848b1ad42>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;31m#Initialize the pretrained embedding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mpretrained_embeddings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTEXT\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvocab\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvectors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membedding\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpretrained_embeddings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpretrained_embeddings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: copy_(): argument 'other' (position 1) must be Tensor, not NoneType"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "REmdwQQplO6s",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch.optim as optim\n",
        "\n",
        "#define optimizer and loss\n",
        "optimizer = optim.Adam(model.parameters())\n",
        "criterion = nn.BCELoss()\n",
        "\n",
        "#define metric\n",
        "def binary_accuracy(preds, y):\n",
        "    #round predictions to the closest integer\n",
        "    rounded_preds = torch.round(preds)\n",
        "    \n",
        "    correct = (rounded_preds == y).float() \n",
        "    acc = correct.sum() / len(correct)\n",
        "    return acc\n",
        "    \n",
        "#push to cuda if available\n",
        "model = model.to(device)\n",
        "criterion = criterion.to(device)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FmgCcdtylawd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train(model, iterator, optimizer, criterion):\n",
        "    \n",
        "    #initialize every epoch \n",
        "    epoch_loss = 0\n",
        "    epoch_acc = 0\n",
        "    \n",
        "    #set the model in training phase\n",
        "    model.train()  \n",
        "    \n",
        "    for batch in iterator:\n",
        "        \n",
        "        #resets the gradients after every batch\n",
        "        optimizer.zero_grad()   \n",
        "        \n",
        "        #retrieve text and no. of words\n",
        "        text, text_lengths = batch.text   \n",
        "        \n",
        "        #convert to 1D tensor\n",
        "        predictions = model(text, text_lengths).squeeze()  \n",
        "        \n",
        "        #compute the loss\n",
        "        loss = criterion(predictions, batch.label)        \n",
        "        \n",
        "        #compute the binary accuracy\n",
        "        acc = binary_accuracy(predictions, batch.label)   \n",
        "        \n",
        "        #backpropage the loss and compute the gradients\n",
        "        loss.backward()       \n",
        "        \n",
        "        #update the weights\n",
        "        optimizer.step()      \n",
        "        \n",
        "        #loss and accuracy\n",
        "        epoch_loss += loss.item()  \n",
        "        epoch_acc += acc.item()    \n",
        "        \n",
        "    return epoch_loss / len(iterator), epoch_acc / len(iterator)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LSV8MEhXlazu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def evaluate(model, iterator, criterion):\n",
        "    \n",
        "    #initialize every epoch\n",
        "    epoch_loss = 0\n",
        "    epoch_acc = 0\n",
        "\n",
        "    #deactivating dropout layers\n",
        "    model.eval()\n",
        "    \n",
        "    #deactivates autograd\n",
        "    with torch.no_grad():\n",
        "    \n",
        "        for batch in iterator:\n",
        "        \n",
        "            #retrieve text and no. of words\n",
        "            text, text_lengths = batch.text\n",
        "            \n",
        "            #convert to 1d tensor\n",
        "            predictions = model(text, text_lengths).squeeze()\n",
        "            \n",
        "            #compute loss and accuracy\n",
        "            loss = criterion(predictions, batch.label)\n",
        "            acc = binary_accuracy(predictions, batch.label)\n",
        "            \n",
        "            #keep track of loss and accuracy\n",
        "            epoch_loss += loss.item()\n",
        "            epoch_acc += acc.item()\n",
        "        \n",
        "    return epoch_loss / len(iterator), epoch_acc / len(iterator)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zsIHByBLla3X",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "N_EPOCHS = 5\n",
        "best_valid_loss = float('inf')\n",
        "\n",
        "for epoch in range(N_EPOCHS):\n",
        "     \n",
        "    #train the model\n",
        "    train_loss, train_acc = train(model, train_iterator, optimizer, criterion)\n",
        "    \n",
        "    #evaluate the model\n",
        "    valid_loss, valid_acc = evaluate(model, valid_iterator, criterion)\n",
        "    \n",
        "    #save the best model\n",
        "    if valid_loss < best_valid_loss:\n",
        "        best_valid_loss = valid_loss\n",
        "        torch.save(model.state_dict(), 'saved_weights.pt')\n",
        "    \n",
        "    print(f'\\tTrain Loss: {train_loss:.3f} | Train Acc: {train_acc*100:.2f}%')\n",
        "    print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. Acc: {valid_acc*100:.2f}%')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JnlylOSvlmKL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#load weights\n",
        "path='/content/saved_weights.pt'\n",
        "model.load_state_dict(torch.load(path));\n",
        "model.eval();\n",
        "\n",
        "#inference \n",
        "import spacy\n",
        "nlp = spacy.load('en')\n",
        "\n",
        "def predict(model, sentence):\n",
        "    tokenized = [tok.text for tok in nlp.tokenizer(sentence)]  #tokenize the sentence \n",
        "    indexed = [TEXT.vocab.stoi[t] for t in tokenized]          #convert to integer sequence\n",
        "    length = [len(indexed)]                                    #compute no. of words\n",
        "    tensor = torch.LongTensor(indexed).to(device)              #convert to tensor\n",
        "    tensor = tensor.unsqueeze(1).T                             #reshape in form of batch,no. of words\n",
        "    length_tensor = torch.LongTensor(length)                   #convert to tensor\n",
        "    prediction = model(tensor, length_tensor)                  #prediction \n",
        "    return prediction.item()               "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "viqijF1YlmNH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#make predictions\n",
        "#predict(model, \"Are there any sports that you don't like?\")\n",
        "\n",
        "#insincere question\n",
        "#predict(model, \"Why Indian girls go crazy about marrying Shri. Rahul Gandhi ji?\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uhLXeqBvoJpS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "predict(model, \"i hate cipro! #antibiotic #nauseous #cf #hospitallife #cysticfibrosis\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZvCJwd6Yo-va",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "predict(model, \"thank god for vyvanse or i would be sleepping on the cash register right now\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JtBihQTmpGV8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "predict(model, \"i'd gladly trade the #mtx  headache for #humira but after 5 months i still don't have the prescription. i function through vitamins &amp; motrin\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pdZ_M7b9pGY5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "predict(model, \"This is a simple tweet\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8ydBUMvGo-x-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}