{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "nn_trial.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "qIKZrgj-PZLB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "28200b28-59d9-47c7-d4bb-381c709fad7e"
      },
      "source": [
        "!pip install emoji"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: emoji in /usr/local/lib/python3.6/dist-packages (0.5.4)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZpOyTneOjJBw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "71ba1bd6-05c2-40e3-f43a-a318a9ceba23"
      },
      "source": [
        "#deal with tensors\n",
        "import torch   \n",
        "\n",
        "#handling text data\n",
        "from torchtext import data   \n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "import sys\n",
        "import os\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "import csv\n",
        "import datetime\n",
        "from bs4 import BeautifulSoup\n",
        "import itertools\n",
        "import emoji"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tnfbiJjpUMn6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#####################################################################################\n",
        "#\n",
        "# DATA CLEANING\n",
        "#\n",
        "#####################################################################################\n",
        "\n",
        "# emoticons\n",
        "def load_dict_smileys():\n",
        "    \n",
        "    return {\n",
        "        \":‑)\":\"smiley\",\n",
        "  \n",
        "      \":-]\":\"smiley\",\n",
        "        \":-3\":\"smiley\",\n",
        "        \":->\":\"smiley\",\n",
        "        \"8-)\":\"smiley\",\n",
        "        \":-}\":\"smiley\",\n",
        "        \":)\":\"smiley\",\n",
        "        \":]\":\"smiley\",\n",
        "        \":3\":\"smiley\",\n",
        "        \":>\":\"smiley\",\n",
        "        \"8)\":\"smiley\",\n",
        "        \":}\":\"smiley\",\n",
        "        \":o)\":\"smiley\",\n",
        "        \":c)\":\"smiley\",\n",
        "        \":^)\":\"smiley\",\n",
        "        \"=]\":\"smiley\",\n",
        "        \"=)\":\"smiley\",\n",
        "        \":-))\":\"smiley\",\n",
        "        \":‑D\":\"smiley\",\n",
        "        \"8‑D\":\"smiley\",\n",
        "        \"x‑D\":\"smiley\",\n",
        "        \"X‑D\":\"smiley\",\n",
        "        \":D\":\"smiley\",\n",
        "        \"8D\":\"smiley\",\n",
        "        \"xD\":\"smiley\",\n",
        "        \"XD\":\"smiley\",\n",
        "        \":‑(\":\"sad\",\n",
        "        \":‑c\":\"sad\",\n",
        "        \":‑<\":\"sad\",\n",
        "        \":‑[\":\"sad\",\n",
        "        \":(\":\"sad\",\n",
        "        \":c\":\"sad\",\n",
        "        \":<\":\"sad\",\n",
        "        \":[\":\"sad\",\n",
        "        \":-||\":\"sad\",\n",
        "        \">:[\":\"sad\",\n",
        "        \":{\":\"sad\",\n",
        "        \":@\":\"sad\",\n",
        "        \">:(\":\"sad\",\n",
        "        \":'‑(\":\"sad\",\n",
        "        \":'(\":\"sad\",\n",
        "        \":‑P\":\"playful\",\n",
        "        \"X‑P\":\"playful\",\n",
        "        \"x‑p\":\"playful\",\n",
        "        \":‑p\":\"playful\",\n",
        "        \":‑Þ\":\"playful\",\n",
        "        \":‑þ\":\"playful\",\n",
        "        \":‑b\":\"playful\",\n",
        "        \":P\":\"playful\",\n",
        "        \"XP\":\"playful\",\n",
        "        \"xp\":\"playful\",\n",
        "        \":p\":\"playful\",\n",
        "        \":Þ\":\"playful\",\n",
        "        \":þ\":\"playful\",\n",
        "        \":b\":\"playful\",\n",
        "        \"<3\":\"love\"\n",
        "        }\n",
        "\n",
        "# self defined contractions\n",
        "def load_dict_contractions():\n",
        "    \n",
        "    return {\n",
        "        \"ain't\":\"is not\",\n",
        "        \"amn't\":\"am not\",\n",
        "        \"aren't\":\"are not\",\n",
        "        \"can't\":\"cannot\",\n",
        "        \"'cause\":\"because\",\n",
        "        \"couldn't\":\"could not\",\n",
        "        \"couldn't've\":\"could not have\",\n",
        "        \"could've\":\"could have\",\n",
        "        \"daren't\":\"dare not\",\n",
        "        \"daresn't\":\"dare not\",\n",
        "        \"dasn't\":\"dare not\",\n",
        "        \"didn't\":\"did not\",\n",
        "        \"doesn't\":\"does not\",\n",
        "        \"don't\":\"do not\",\n",
        "        \"e'er\":\"ever\",\n",
        "        \"em\":\"them\",\n",
        "        \"everyone's\":\"everyone is\",\n",
        "        \"finna\":\"fixing to\",\n",
        "        \"gimme\":\"give me\",\n",
        "        \"gonna\":\"going to\",\n",
        "        \"gon't\":\"go not\",\n",
        "        \"gotta\":\"got to\",\n",
        "        \"hadn't\":\"had not\",\n",
        "        \"hasn't\":\"has not\",\n",
        "        \"haven't\":\"have not\",\n",
        "        \"he'd\":\"he would\",\n",
        "        \"he'll\":\"he will\",\n",
        "        \"he's\":\"he is\",\n",
        "        \"he've\":\"he have\",\n",
        "        \"how'd\":\"how would\",\n",
        "        \"how'll\":\"how will\",\n",
        "        \"how're\":\"how are\",\n",
        "        \"how's\":\"how is\",\n",
        "        \"I'd\":\"I would\",\n",
        "        \"I'll\":\"I will\",\n",
        "        \"I'm\":\"I am\",\n",
        "        \"I'm'a\":\"I am about to\",\n",
        "        \"I'm'o\":\"I am going to\",\n",
        "        \"isn't\":\"is not\",\n",
        "        \"it'd\":\"it would\",\n",
        "        \"it'll\":\"it will\",\n",
        "        \"it's\":\"it is\",\n",
        "        \"I've\":\"I have\",\n",
        "        \"kinda\":\"kind of\",\n",
        "        \"let's\":\"let us\",\n",
        "        \"mayn't\":\"may not\",\n",
        "        \"may've\":\"may have\",\n",
        "        \"mightn't\":\"might not\",\n",
        "        \"might've\":\"might have\",\n",
        "        \"mustn't\":\"must not\",\n",
        "        \"mustn't've\":\"must not have\",\n",
        "        \"must've\":\"must have\",\n",
        "        \"needn't\":\"need not\",\n",
        "        \"ne'er\":\"never\",\n",
        "        \"o'\":\"of\",\n",
        "        \"o'er\":\"over\",\n",
        "        \"ol'\":\"old\",\n",
        "        \"oughtn't\":\"ought not\",\n",
        "        \"shalln't\":\"shall not\",\n",
        "        \"shan't\":\"shall not\",\n",
        "        \"she'd\":\"she would\",\n",
        "        \"she'll\":\"she will\",\n",
        "        \"she's\":\"she is\",\n",
        "        \"shouldn't\":\"should not\",\n",
        "        \"shouldn't've\":\"should not have\",\n",
        "        \"should've\":\"should have\",\n",
        "        \"somebody's\":\"somebody is\",\n",
        "        \"someone's\":\"someone is\",\n",
        "        \"something's\":\"something is\",\n",
        "        \"that'd\":\"that would\",\n",
        "        \"that'll\":\"that will\",\n",
        "        \"that're\":\"that are\",\n",
        "        \"that's\":\"that is\",\n",
        "        \"there'd\":\"there would\",\n",
        "        \"there'll\":\"there will\",\n",
        "        \"there're\":\"there are\",\n",
        "        \"there's\":\"there is\",\n",
        "        \"these're\":\"these are\",\n",
        "        \"they'd\":\"they would\",\n",
        "        \"they'll\":\"they will\",\n",
        "        \"they're\":\"they are\",\n",
        "        \"they've\":\"they have\",\n",
        "        \"this's\":\"this is\",\n",
        "        \"those're\":\"those are\",\n",
        "        \"'tis\":\"it is\",\n",
        "        \"'twas\":\"it was\",\n",
        "        \"wanna\":\"want to\",\n",
        "        \"wasn't\":\"was not\",\n",
        "        \"we'd\":\"we would\",\n",
        "        \"we'd've\":\"we would have\",\n",
        "        \"we'll\":\"we will\",\n",
        "        \"we're\":\"we are\",\n",
        "        \"weren't\":\"were not\",\n",
        "        \"we've\":\"we have\",\n",
        "        \"what'd\":\"what did\",\n",
        "        \"what'll\":\"what will\",\n",
        "        \"what're\":\"what are\",\n",
        "        \"what's\":\"what is\",\n",
        "        \"what've\":\"what have\",\n",
        "        \"when's\":\"when is\",\n",
        "        \"where'd\":\"where did\",\n",
        "        \"where're\":\"where are\",\n",
        "        \"where's\":\"where is\",\n",
        "        \"where've\":\"where have\",\n",
        "        \"which's\":\"which is\",\n",
        "        \"who'd\":\"who would\",\n",
        "        \"who'd've\":\"who would have\",\n",
        "        \"who'll\":\"who will\",\n",
        "        \"who're\":\"who are\",\n",
        "        \"who's\":\"who is\",\n",
        "        \"who've\":\"who have\",\n",
        "        \"why'd\":\"why did\",\n",
        "        \"why're\":\"why are\",\n",
        "        \"why's\":\"why is\",\n",
        "        \"won't\":\"will not\",\n",
        "        \"wouldn't\":\"would not\",\n",
        "        \"would've\":\"would have\",\n",
        "        \"y'all\":\"you all\",\n",
        "        \"you'd\":\"you would\",\n",
        "        \"you'll\":\"you will\",\n",
        "        \"you're\":\"you are\",\n",
        "        \"you've\":\"you have\",\n",
        "        \"Whatcha\":\"What are you\",\n",
        "        \"luv\":\"love\",\n",
        "        \"sux\":\"sucks\"\n",
        "        }"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ifa0GG8_kgMa",
        "colab_type": "code",
        "outputId": "b16afc69-338d-4458-be8e-a8cf21ca1e62",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YwoDcJI9rHRs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import re\n",
        "import string\n",
        "from bs4 import BeautifulSoup\n",
        "\n",
        "#for tweet in tweet_data:\n",
        "def preprocess_tweet(tweet):\n",
        "    #Escaping HTML characters\n",
        "    tweet = BeautifulSoup(tweet).get_text()\n",
        "   \n",
        "    #Special case not handled previously.\n",
        "    tweet = tweet.replace('\\x92',\"'\")\n",
        "    \n",
        "    #Removal of hastags/account\n",
        "    tweet = ' '.join(re.sub(\"(@[A-Za-z0-9]+)|(#[A-Za-z0-9]+)\", \" \", tweet).split())\n",
        "    \n",
        "    #Removal of address\n",
        "    tweet = ' '.join(re.sub(\"(\\w+:\\/\\/\\S+)\", \" \", tweet).split())\n",
        "    \n",
        "    #Removal of Punctuation\n",
        "    tweet = ' '.join(re.sub(\"[\\.\\,\\!\\?\\<\\>\\:\\;\\-\\=]\", \" \", tweet).split())\n",
        "    \n",
        "    #Lower case\n",
        "    tweet = tweet.lower()\n",
        "    \n",
        "    #CONTRACTIONS source: https://en.wikipedia.org/wiki/Contraction_%28grammar%29\n",
        "    CONTRACTIONS = load_dict_contractions()\n",
        "    tweet = tweet.replace(\"’\",\"'\")\n",
        "    words = tweet.split()\n",
        "    reformed = [CONTRACTIONS[word] if word in CONTRACTIONS else word for word in words]\n",
        "    tweet = \" \".join(reformed)\n",
        "    \n",
        "    # Standardizing words\n",
        "    tweet = ''.join(''.join(s)[:2] for _, s in itertools.groupby(tweet))\n",
        "    \n",
        "    #Deal with emoticons source: https://en.wikipedia.org/wiki/List_of_emoticons\n",
        "    SMILEY = load_dict_smileys()  \n",
        "    words = tweet.split()\n",
        "    reformed = [SMILEY[word] if word in SMILEY else word for word in words]\n",
        "    tweet = \" \".join(reformed)\n",
        "    \n",
        "    #Deal with emojis\n",
        "    tweet = emoji.demojize(tweet)\n",
        "\n",
        "    tweet = tweet.replace(\":\",\" \")\n",
        "    tweet = ' '.join(tweet.split())\n",
        "\n",
        "    return tweet\n",
        "    \n",
        "        \n",
        "#     # remove special characters, numbers, punctuations\n",
        "#     text = text.replace(\"[^a-zA-Z#]\", \" \")\n",
        "#     # Additional clean up : removing words less than 3 chars, and remove space at the beginning and the end\n",
        "#     text = re.sub(r'\\W*\\b\\w{1,3}\\b', '', text)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2icyEytaOTqm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 384
        },
        "outputId": "fdec0279-4e7a-49f7-e4bc-3cdbb6f74190"
      },
      "source": [
        "count = 0\n",
        "usecols = (2,4)\n",
        "dataframe = pd.read_table(\"/content/task1_training.tsv\",usecols=usecols)\n",
        "with open('SE_train.tsv', 'w') as out_file:\n",
        "  tsv_writer = csv.writer(out_file, delimiter='\\t')\n",
        "  tsv_writer.writerow(['text','label'])\n",
        "  for tweet in dataframe.iterrows():\n",
        "    if tweet[1][1] == 0:\n",
        "      count = count+1\n",
        "    if tweet[1][1] == 0 and count > 1000:\n",
        "      continue\n",
        "    tsv_writer.writerow([preprocess_tweet(tweet[1][0]), str(tweet[1][1])])\n",
        "    "
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/bs4/__init__.py:336: UserWarning: \"https://t.co/oewqnWJA4k\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
            "  ' that document to Beautiful Soup.' % decoded_markup\n",
            "/usr/local/lib/python3.6/dist-packages/bs4/__init__.py:336: UserWarning: \"https://t.co/29HB3YRChW\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
            "  ' that document to Beautiful Soup.' % decoded_markup\n",
            "/usr/local/lib/python3.6/dist-packages/bs4/__init__.py:336: UserWarning: \"https://t.co/SrTqQTcHuT\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
            "  ' that document to Beautiful Soup.' % decoded_markup\n",
            "/usr/local/lib/python3.6/dist-packages/bs4/__init__.py:336: UserWarning: \"http://t.co/tGe0fGhtwa\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
            "  ' that document to Beautiful Soup.' % decoded_markup\n",
            "/usr/local/lib/python3.6/dist-packages/bs4/__init__.py:336: UserWarning: \"https://t.co/sFfnztCggN\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
            "  ' that document to Beautiful Soup.' % decoded_markup\n",
            "/usr/local/lib/python3.6/dist-packages/bs4/__init__.py:336: UserWarning: \"https://t.co/rHxH6K7pVG\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
            "  ' that document to Beautiful Soup.' % decoded_markup\n",
            "/usr/local/lib/python3.6/dist-packages/bs4/__init__.py:336: UserWarning: \"https://t.co/gzSfdgQpKE\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
            "  ' that document to Beautiful Soup.' % decoded_markup\n",
            "/usr/local/lib/python3.6/dist-packages/bs4/__init__.py:336: UserWarning: \"https://t.co/W3Lj5TRi3C\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
            "  ' that document to Beautiful Soup.' % decoded_markup\n",
            "/usr/local/lib/python3.6/dist-packages/bs4/__init__.py:336: UserWarning: \"http://t.co/bNfwDkhGkU\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
            "  ' that document to Beautiful Soup.' % decoded_markup\n",
            "/usr/local/lib/python3.6/dist-packages/bs4/__init__.py:336: UserWarning: \"https://t.co/nidyKpR7oC\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
            "  ' that document to Beautiful Soup.' % decoded_markup\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fZXI3oxWP1Cs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "usecols = (2,4)\n",
        "dataframe = pd.read_table(\"/content/task1_validation.tsv\",usecols=usecols)\n",
        "with open('SE_valid.tsv', 'w') as out_file:\n",
        "  tsv_writer = csv.writer(out_file, delimiter='\\t')\n",
        "  tsv_writer.writerow(['text','label'])\n",
        "  for tweet in dataframe.iterrows():\n",
        "    if tweet[1][1] == 1:\n",
        "      tsv_writer.writerow([preprocess_tweet(tweet[1][0]), str(tweet[1][1])])\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z2_E41HNju_q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Reproducing same results\n",
        "SEED = 2019\n",
        "\n",
        "#Torch\n",
        "torch.manual_seed(SEED)\n",
        "\n",
        "#Cuda algorithms\n",
        "torch.backends.cudnn.deterministic = True "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0NWISrdjjx0e",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "TEXT = data.Field(tokenize='spacy',batch_first=True, lower=True,  include_lengths=True)\n",
        "LABEL = data.LabelField(dtype = torch.float,batch_first=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eTzdUzk2j1ni",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "fields = [('text',TEXT), ('label', LABEL)]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-8sJ3Fphj4cu",
        "colab_type": "code",
        "outputId": "fdb931b4-5ef2-4ba8-e9d1-22818c307c4e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "#loading custom dataset\n",
        "train_data = data.TabularDataset(path = '/content/task1_training.tsv',format = 'tsv',fields = fields,skip_header = True)\n",
        "valid_data = data.TabularDataset(path = '/content/task1_validation.tsv',format = 'tsv',fields = fields,skip_header = True)\n",
        "\n",
        "#print preprocessed text\n",
        "print(vars(train_data.examples[0]))"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'text': ['854534152070279168'], 'label': '2147874931'}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RVchTZfJlL3i",
        "colab_type": "code",
        "outputId": "70938286-4af0-4386-85b3-f099dd9c10a2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 471
        }
      },
      "source": [
        "#initialize glove embeddings\n",
        "TEXT.build_vocab(train_data,min_freq=3,vectors = \"glove.6B.100d\")  \n",
        "LABEL.build_vocab(train_data)\n",
        "\n",
        "#No. of unique tokens in text\n",
        "print(\"Size of TEXT vocabulary:\",len(TEXT.vocab))\n",
        "\n",
        "#No. of unique tokens in label\n",
        "print(\"Size of LABEL vocabulary:\",len(LABEL.vocab))\n",
        "\n",
        "#Commonly used words\n",
        "print(TEXT.vocab.freqs.most_common(10))  \n",
        "\n",
        "#Word dictionary\n",
        "print(TEXT.vocab.stoi) "
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            ".vector_cache/glove.6B.zip: 0.00B [01:17, ?B/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torchtext/vocab.py\u001b[0m in \u001b[0;36mcache\u001b[0;34m(self, name, cache, url, max_vectors)\u001b[0m\n\u001b[1;32m    312\u001b[0m                         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 313\u001b[0;31m                             \u001b[0murlretrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreporthook\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreporthook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    314\u001b[0m                         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# remove the partial zip file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/urllib/request.py\u001b[0m in \u001b[0;36murlretrieve\u001b[0;34m(url, filename, reporthook, data)\u001b[0m\n\u001b[1;32m    247\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 248\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0mcontextlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclosing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murlopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    249\u001b[0m         \u001b[0mheaders\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/urllib/request.py\u001b[0m in \u001b[0;36murlopen\u001b[0;34m(url, data, timeout, cafile, capath, cadefault, context)\u001b[0m\n\u001b[1;32m    222\u001b[0m         \u001b[0mopener\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_opener\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 223\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mopener\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    224\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/urllib/request.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(self, fullurl, data, timeout)\u001b[0m\n\u001b[1;32m    525\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 526\u001b[0;31m         \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_open\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    527\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/urllib/request.py\u001b[0m in \u001b[0;36m_open\u001b[0;34m(self, req, data)\u001b[0m\n\u001b[1;32m    543\u001b[0m         result = self._call_chain(self.handle_open, protocol, protocol +\n\u001b[0;32m--> 544\u001b[0;31m                                   '_open', req)\n\u001b[0m\u001b[1;32m    545\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/urllib/request.py\u001b[0m in \u001b[0;36m_call_chain\u001b[0;34m(self, chain, kind, meth_name, *args)\u001b[0m\n\u001b[1;32m    503\u001b[0m             \u001b[0mfunc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmeth_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 504\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    505\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mresult\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/urllib/request.py\u001b[0m in \u001b[0;36mhttp_open\u001b[0;34m(self, req)\u001b[0m\n\u001b[1;32m   1345\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mhttp_open\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreq\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1346\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdo_open\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhttp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclient\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mHTTPConnection\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreq\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1347\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/urllib/request.py\u001b[0m in \u001b[0;36mdo_open\u001b[0;34m(self, http_class, req, **http_conn_args)\u001b[0m\n\u001b[1;32m   1320\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mURLError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1321\u001b[0;31m             \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetresponse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1322\u001b[0m         \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/http/client.py\u001b[0m in \u001b[0;36mgetresponse\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1345\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1346\u001b[0;31m                 \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbegin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1347\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mConnectionError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/http/client.py\u001b[0m in \u001b[0;36mbegin\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    306\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 307\u001b[0;31m             \u001b[0mversion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreason\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_read_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    308\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mstatus\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mCONTINUE\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/http/client.py\u001b[0m in \u001b[0;36m_read_status\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    267\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_read_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 268\u001b[0;31m         \u001b[0mline\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_MAXLINE\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"iso-8859-1\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    269\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0m_MAXLINE\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/socket.py\u001b[0m in \u001b[0;36mreadinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    585\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 586\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_into\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    587\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: ",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-59-98c0aee97620>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mTEXT\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild_vocab\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmin_freq\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvectors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"glove.6B.100d\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mLABEL\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild_vocab\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m#No. of unique tokens in text\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Size of TEXT vocabulary:\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTEXT\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvocab\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torchtext/data/field.py\u001b[0m in \u001b[0;36mbuild_vocab\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    271\u001b[0m                             self.eos_token]\n\u001b[1;32m    272\u001b[0m             if tok is not None))\n\u001b[0;32m--> 273\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvocab\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvocab_cls\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcounter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mspecials\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mspecials\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    274\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    275\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mnumericalize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torchtext/vocab.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, counter, max_size, min_freq, specials, vectors, unk_init, vectors_cache, specials_first)\u001b[0m\n\u001b[1;32m     86\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvectors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mvectors\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 88\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_vectors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvectors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munk_init\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0munk_init\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcache\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvectors_cache\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     89\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0munk_init\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mvectors_cache\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torchtext/vocab.py\u001b[0m in \u001b[0;36mload_vectors\u001b[0;34m(self, vectors, **kwargs)\u001b[0m\n\u001b[1;32m    145\u001b[0m                         \"vectors are {}\".format(\n\u001b[1;32m    146\u001b[0m                             vector, list(pretrained_aliases.keys())))\n\u001b[0;32m--> 147\u001b[0;31m                 \u001b[0mvectors\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpretrained_aliases\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mvector\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    148\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvector\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mVectors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m                 raise ValueError(\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torchtext/vocab.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, name, dim, **kwargs)\u001b[0m\n\u001b[1;32m    399\u001b[0m         \u001b[0murl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    400\u001b[0m         \u001b[0mname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'glove.{}.{}d.txt'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 401\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mGloVe\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    402\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    403\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torchtext/vocab.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, name, cache, url, unk_init, max_vectors)\u001b[0m\n\u001b[1;32m    278\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    279\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munk_init\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0munk_init\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0munk_init\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 280\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcache\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_vectors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_vectors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    281\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    282\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__getitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtoken\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torchtext/vocab.py\u001b[0m in \u001b[0;36mcache\u001b[0;34m(self, name, cache, url, max_vectors)\u001b[0m\n\u001b[1;32m    313\u001b[0m                             \u001b[0murlretrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreporthook\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreporthook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    314\u001b[0m                         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# remove the partial zip file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 315\u001b[0;31m                             \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mremove\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    316\u001b[0m                             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    317\u001b[0m                 \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Extracting vectors into {}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcache\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '.vector_cache/glove.6B.zip'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RZdAGLBjlOts",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#check whether cuda is available\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')  \n",
        "\n",
        "#set batch size\n",
        "BATCH_SIZE = 64\n",
        "\n",
        "#Load an iterator\n",
        "train_iterator, valid_iterator = data.BucketIterator.splits(\n",
        "    (train_data, valid_data), \n",
        "    batch_size = BATCH_SIZE,\n",
        "    sort_key = lambda x: len(x.text),\n",
        "    sort_within_batch=True,\n",
        "    device = device)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0C2AjXRGlOxA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "class classifier(nn.Module):\n",
        "    \n",
        "    #define all the layers used in model\n",
        "    def __init__(self, vocab_size, embedding_dim, hidden_dim, output_dim, n_layers, \n",
        "                 bidirectional, dropout):\n",
        "        \n",
        "        #Constructor\n",
        "        super().__init__()          \n",
        "        \n",
        "        #embedding layer\n",
        "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
        "        \n",
        "        #lstm layer\n",
        "        self.lstm = nn.LSTM(embedding_dim, \n",
        "                           hidden_dim, \n",
        "                           num_layers=n_layers, \n",
        "                           bidirectional=bidirectional, \n",
        "                           dropout=dropout,\n",
        "                           batch_first=True)\n",
        "        \n",
        "        #dense layer\n",
        "        self.fc = nn.Linear(hidden_dim * 2, output_dim)\n",
        "        \n",
        "        #activation function\n",
        "        self.act = nn.Sigmoid()\n",
        "        \n",
        "    def forward(self, text, text_lengths):\n",
        "        \n",
        "        #text = [batch size,sent_length]\n",
        "        embedded = self.embedding(text)\n",
        "        #embedded = [batch size, sent_len, emb dim]\n",
        "      \n",
        "        #packed sequence\n",
        "        packed_embedded = nn.utils.rnn.pack_padded_sequence(embedded, text_lengths,batch_first=True)\n",
        "        \n",
        "        packed_output, (hidden, cell) = self.lstm(packed_embedded)\n",
        "        #hidden = [batch size, num layers * num directions,hid dim]\n",
        "        #cell = [batch size, num layers * num directions,hid dim]\n",
        "        \n",
        "        #concat the final forward and backward hidden state\n",
        "        hidden = torch.cat((hidden[-2,:,:], hidden[-1,:,:]), dim = 1)\n",
        "                \n",
        "        #hidden = [batch size, hid dim * num directions]\n",
        "        dense_outputs=self.fc(hidden)\n",
        "\n",
        "        #Final activation function\n",
        "        outputs=self.act(dense_outputs)\n",
        "        \n",
        "        return outputs"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B9dcueJElO0P",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#define hyperparameters\n",
        "size_of_vocab = len(TEXT.vocab)\n",
        "embedding_dim = 100\n",
        "num_hidden_nodes = 32\n",
        "num_output_nodes = 1\n",
        "num_layers = 2\n",
        "bidirection = True\n",
        "dropout = 0.2\n",
        "\n",
        "#instantiate the model\n",
        "model = classifier(size_of_vocab, embedding_dim, num_hidden_nodes,num_output_nodes, num_layers, \n",
        "                   bidirectional = True, dropout = dropout)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3H5OYzjglO31",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "#architecture\n",
        "print(model)\n",
        "\n",
        "#No. of trianable parameters\n",
        "def count_parameters(model):\n",
        "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "    \n",
        "print(f'The model has {count_parameters(model):,} trainable parameters')\n",
        "\n",
        "#Initialize the pretrained embedding\n",
        "pretrained_embeddings = TEXT.vocab.vectors\n",
        "model.embedding.weight.data.copy_(pretrained_embeddings)\n",
        "\n",
        "print(pretrained_embeddings.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "REmdwQQplO6s",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch.optim as optim\n",
        "\n",
        "#define optimizer and loss\n",
        "optimizer = optim.Adam(model.parameters())\n",
        "criterion = nn.BCELoss()\n",
        "\n",
        "#define metric\n",
        "def binary_accuracy(preds, y):\n",
        "    #round predictions to the closest integer\n",
        "    rounded_preds = torch.round(preds)\n",
        "    \n",
        "    correct = (rounded_preds == y).float() \n",
        "    acc = correct.sum() / len(correct)\n",
        "    return acc\n",
        "    \n",
        "#push to cuda if available\n",
        "model = model.to(device)\n",
        "criterion = criterion.to(device)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FmgCcdtylawd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train(model, iterator, optimizer, criterion):\n",
        "    \n",
        "    #initialize every epoch \n",
        "    epoch_loss = 0\n",
        "    epoch_acc = 0\n",
        "    \n",
        "    #set the model in training phase\n",
        "    model.train()  \n",
        "    \n",
        "    for batch in iterator:\n",
        "        \n",
        "        #resets the gradients after every batch\n",
        "        optimizer.zero_grad()   \n",
        "        \n",
        "        #retrieve text and no. of words\n",
        "        text, text_lengths = batch.text   \n",
        "        \n",
        "        #convert to 1D tensor\n",
        "        predictions = model(text, text_lengths).squeeze()  \n",
        "        \n",
        "        #compute the loss\n",
        "        loss = criterion(predictions, batch.label)        \n",
        "        \n",
        "        #compute the binary accuracy\n",
        "        acc = binary_accuracy(predictions, batch.label)   \n",
        "        \n",
        "        #backpropage the loss and compute the gradients\n",
        "        loss.backward()       \n",
        "        \n",
        "        #update the weights\n",
        "        optimizer.step()      \n",
        "        \n",
        "        #loss and accuracy\n",
        "        epoch_loss += loss.item()  \n",
        "        epoch_acc += acc.item()    \n",
        "        \n",
        "    return epoch_loss / len(iterator), epoch_acc / len(iterator)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LSV8MEhXlazu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def evaluate(model, iterator, criterion):\n",
        "    \n",
        "    #initialize every epoch\n",
        "    epoch_loss = 0\n",
        "    epoch_acc = 0\n",
        "\n",
        "    #deactivating dropout layers\n",
        "    model.eval()\n",
        "    \n",
        "    #deactivates autograd\n",
        "    with torch.no_grad():\n",
        "    \n",
        "        for batch in iterator:\n",
        "        \n",
        "            #retrieve text and no. of words\n",
        "            text, text_lengths = batch.text\n",
        "            \n",
        "            #convert to 1d tensor\n",
        "            predictions = model(text, text_lengths).squeeze()\n",
        "            \n",
        "            #compute loss and accuracy\n",
        "            loss = criterion(predictions, batch.label)\n",
        "            acc = binary_accuracy(predictions, batch.label)\n",
        "            \n",
        "            #keep track of loss and accuracy\n",
        "            epoch_loss += loss.item()\n",
        "            epoch_acc += acc.item()\n",
        "        \n",
        "    return epoch_loss / len(iterator), epoch_acc / len(iterator)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zsIHByBLla3X",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "N_EPOCHS = 5\n",
        "best_valid_loss = float('inf')\n",
        "\n",
        "for epoch in range(N_EPOCHS):\n",
        "     \n",
        "    #train the model\n",
        "    train_loss, train_acc = train(model, train_iterator, optimizer, criterion)\n",
        "    \n",
        "    #evaluate the model\n",
        "    valid_loss, valid_acc = evaluate(model, valid_iterator, criterion)\n",
        "    \n",
        "    #save the best model\n",
        "    if valid_loss < best_valid_loss:\n",
        "        best_valid_loss = valid_loss\n",
        "        torch.save(model.state_dict(), 'saved_weights.pt')\n",
        "    \n",
        "    print(f'\\tTrain Loss: {train_loss:.3f} | Train Acc: {train_acc*100:.2f}%')\n",
        "    print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. Acc: {valid_acc*100:.2f}%')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JnlylOSvlmKL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#load weights\n",
        "path='/content/saved_weights.pt'\n",
        "model.load_state_dict(torch.load(path));\n",
        "model.eval();\n",
        "\n",
        "#inference \n",
        "import spacy\n",
        "nlp = spacy.load('en')\n",
        "\n",
        "def predict(model, sentence):\n",
        "    tokenized = [tok.text for tok in nlp.tokenizer(sentence)]  #tokenize the sentence \n",
        "    indexed = [TEXT.vocab.stoi[t] for t in tokenized]          #convert to integer sequence\n",
        "    length = [len(indexed)]                                    #compute no. of words\n",
        "    tensor = torch.LongTensor(indexed).to(device)              #convert to tensor\n",
        "    tensor = tensor.unsqueeze(1).T                             #reshape in form of batch,no. of words\n",
        "    length_tensor = torch.LongTensor(length)                   #convert to tensor\n",
        "    prediction = model(tensor, length_tensor)                  #prediction \n",
        "    return prediction.item()               "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "viqijF1YlmNH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#make predictions\n",
        "#predict(model, \"Are there any sports that you don't like?\")\n",
        "\n",
        "#insincere question\n",
        "#predict(model, \"Why Indian girls go crazy about marrying Shri. Rahul Gandhi ji?\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uhLXeqBvoJpS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "predict(model, \"i hate cipro! #antibiotic #nauseous #cf #hospitallife #cysticfibrosis\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZvCJwd6Yo-va",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "predict(model, \"thank god for vyvanse or i would be sleepping on the cash register right now\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JtBihQTmpGV8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "predict(model, \"i'd gladly trade the #mtx  headache for #humira but after 5 months i still don't have the prescription. i function through vitamins &amp; motrin\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pdZ_M7b9pGY5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "predict(model, \"This is a simple tweet\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8ydBUMvGo-x-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}